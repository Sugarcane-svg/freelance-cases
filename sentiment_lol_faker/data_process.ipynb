{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# from konlpy.tag import Kkma\n",
    "from langdetect import detect\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('油管.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2795 entries, 0 to 2794\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   媒体ID    2795 non-null   object\n",
      " 1   账号ID    2795 non-null   object\n",
      " 2   账号名     2795 non-null   object\n",
      " 3   粉丝量     2795 non-null   int64 \n",
      " 4   标题      2795 non-null   object\n",
      " 5   简介      2778 non-null   object\n",
      " 6   发布日期    2795 non-null   object\n",
      " 7   URL     2795 non-null   object\n",
      " 8   视频时长    2795 non-null   int64 \n",
      " 9   观看量     2795 non-null   int64 \n",
      " 10  点赞量     2795 non-null   int64 \n",
      " 11  评论量     2795 non-null   int64 \n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 262.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2795"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if 媒体ID is unique\n",
    "len(data['媒体ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['leagueoflegends', 'T1_Faker'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if 账号名 and 账号ID mean the same\n",
    "data['账号名'].unique()\n",
    "data['账号ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop no need columns\n",
    "data.drop(['账号名', 'URL'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "媒体ID     0\n",
       "账号ID     0\n",
       "粉丝量      0\n",
       "标题       0\n",
       "简介      17\n",
       "发布日期     0\n",
       "视频时长     0\n",
       "观看量      0\n",
       "点赞量      0\n",
       "评论量      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NA\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 发布时间 = 日期 + 时间\n",
    "data['post_date'] = data['发布日期'].apply(lambda x: x.split(' ')[0])\n",
    "data['post_time'] = data['发布日期'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "# drop 发布日期\n",
    "data.drop('发布日期', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on 标题, the data has to split into 2 parts: english and korean\n",
    "data['language_tag'] = data['标题'].apply(lambda x: int(detect(x) == 'ko'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = data[data['language_tag'] == 0][['媒体ID', '账号ID', '标题', '简介']]\n",
    "ko = data[data['language_tag'] == 1][['媒体ID', '账号ID', '标题', '简介']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = GoogleTranslator(source='ko', target='en')\n",
    "\n",
    "ko['简介'] = ko['简介'].apply(lambda x : translator.translate(x))\n",
    "ko['标题'] = ko['标题'].apply(lambda x : translator.translate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkma = Kkma()\n",
    "# ko['标题'] = ko['标题'].apply(lambda x: re.split(r'[^\\w\\s]', x))\n",
    "# ko['简介'] = ko['简介'].apply(lambda x: re.sub(r'http\\S+', '', x)).apply(lambda x: re.sub(r'[^\\w\\s]', '', x)).apply(lambda x: re.sub(r'\\n', '', x))\n",
    "# ko['word_pos_tag'] = ko['简介'].apply(lambda x: kkma.pos(re.sub(r'[^\\w\\s]', '', x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_data = pd.concat([en, ko], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>媒体ID</th>\n",
       "      <th>账号ID</th>\n",
       "      <th>标题</th>\n",
       "      <th>简介</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J_TQK480XDk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Champion Insights: Ambessa | Behind-the-scenes...</td>\n",
       "      <td>A look behind-the-scenes at how Ambessa Medard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3dAb0HADFYU</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Ambessa Champion Spotlight (feat. Mylon) | Gam...</td>\n",
       "      <td>Conquer the top lane and beyond with Ambessa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o69dtlznmug</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Ambessa: The Matriarch of War | Champion Trail...</td>\n",
       "      <td>You think yourself a wolf? Prove it. Ambessa i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s5u1_XUcrSc</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Jinx Fixes Everything Trailer | Gameplay - Lea...</td>\n",
       "      <td>Play as Jinx to explore your favorite haunts i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R8OqqaBwcl8</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Linkin Park - Heavy Is The Crown | Worlds 2024...</td>\n",
       "      <td>Watch the live performance of Heavy Is The Cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>bJyiMBgBTR0</td>\n",
       "      <td>T1_Faker</td>\n",
       "      <td>SKT T1 Faker Syndra / I forgot that Faker was ...</td>\n",
       "      <td>'Classic Wave' is the ID Faker used during his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>cArBUMfGI9Q</td>\n",
       "      <td>T1_Faker</td>\n",
       "      <td>SKT T1 Faker Zed / KDA 12/2/6 Faker's Mid Zed!...</td>\n",
       "      <td>Here is Faker's March 10th Mid Zed Solo Rank v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>lBvq9VNLJiU</td>\n",
       "      <td>T1_Faker</td>\n",
       "      <td>FAKER: TOP Fiora Faker's Fiora! This is how yo...</td>\n",
       "      <td>Faker's March 6th Top Fiora Solo Rank! Short a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>nhP8-FZ0G3E</td>\n",
       "      <td>T1_Faker</td>\n",
       "      <td>SKT T1 Faker Aatrox / Patched Aatrox! Faker al...</td>\n",
       "      <td>Here is Faker's March 9 Jungle Aatrox Solo Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>1UwYZIb1xTc</td>\n",
       "      <td>T1_Faker</td>\n",
       "      <td>[ Faker's Talk ] Faker made fun of Lee Sin, a ...</td>\n",
       "      <td>* Faker Twitch: https://www.twitch.tv/faker\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2778 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             媒体ID             账号ID  \\\n",
       "0     J_TQK480XDk  leagueoflegends   \n",
       "1     3dAb0HADFYU  leagueoflegends   \n",
       "2     o69dtlznmug  leagueoflegends   \n",
       "3     s5u1_XUcrSc  leagueoflegends   \n",
       "4     R8OqqaBwcl8  leagueoflegends   \n",
       "...           ...              ...   \n",
       "2773  bJyiMBgBTR0         T1_Faker   \n",
       "2774  cArBUMfGI9Q         T1_Faker   \n",
       "2775  lBvq9VNLJiU         T1_Faker   \n",
       "2776  nhP8-FZ0G3E         T1_Faker   \n",
       "2777  1UwYZIb1xTc         T1_Faker   \n",
       "\n",
       "                                                     标题  \\\n",
       "0     Champion Insights: Ambessa | Behind-the-scenes...   \n",
       "1     Ambessa Champion Spotlight (feat. Mylon) | Gam...   \n",
       "2     Ambessa: The Matriarch of War | Champion Trail...   \n",
       "3     Jinx Fixes Everything Trailer | Gameplay - Lea...   \n",
       "4     Linkin Park - Heavy Is The Crown | Worlds 2024...   \n",
       "...                                                 ...   \n",
       "2773  SKT T1 Faker Syndra / I forgot that Faker was ...   \n",
       "2774  SKT T1 Faker Zed / KDA 12/2/6 Faker's Mid Zed!...   \n",
       "2775  FAKER: TOP Fiora Faker's Fiora! This is how yo...   \n",
       "2776  SKT T1 Faker Aatrox / Patched Aatrox! Faker al...   \n",
       "2777  [ Faker's Talk ] Faker made fun of Lee Sin, a ...   \n",
       "\n",
       "                                                     简介  \n",
       "0     A look behind-the-scenes at how Ambessa Medard...  \n",
       "1     Conquer the top lane and beyond with Ambessa, ...  \n",
       "2     You think yourself a wolf? Prove it. Ambessa i...  \n",
       "3     Play as Jinx to explore your favorite haunts i...  \n",
       "4     Watch the live performance of Heavy Is The Cro...  \n",
       "...                                                 ...  \n",
       "2773  'Classic Wave' is the ID Faker used during his...  \n",
       "2774  Here is Faker's March 10th Mid Zed Solo Rank v...  \n",
       "2775  Faker's March 6th Top Fiora Solo Rank! Short a...  \n",
       "2776  Here is Faker's March 9 Jungle Aatrox Solo Ran...  \n",
       "2777  * Faker Twitch: https://www.twitch.tv/faker\\n\\...  \n",
       "\n",
       "[2778 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English process\n",
    "# nltk.download()   --- if not run success, uncomment the line, wait until download the close the window\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_clean_words(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [w.strip() for w in words]\n",
    "    no_stops = [w for w in words if not w in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in no_stops]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dimension tables\n",
    "\n",
    "words_dim = translated_data[['媒体ID', '简介']]\n",
    "title_dim = translated_data[['媒体ID', '标题']]\n",
    "id_dim = pd.DataFrame({'id':['leagueoflegends', 'T1_Faker'], 'name':['League of Legends', 'Faker']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/j2w_t12n7sxby0bnmzq56hjm0000gn/T/ipykernel_77592/3099777941.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  words_dim['clean_words'] = words_dim['简介'].apply(get_clean_words).apply(lambda x: pos_tag(x))\n",
      "/var/folders/jy/j2w_t12n7sxby0bnmzq56hjm0000gn/T/ipykernel_77592/3099777941.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  title_dim['标题'] = title_dim['标题'].apply(lambda x: re.split(r'[^\\w\\s]', x))\n"
     ]
    }
   ],
   "source": [
    "words_dim['clean_words'] = words_dim['简介'].apply(get_clean_words).apply(lambda x: pos_tag(x))\n",
    "title_dim['标题'] = title_dim['标题'].apply(lambda x: re.split(r'[^\\w\\s]', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = pd.Series()\n",
    "pos_tag = pd.Series()\n",
    "\n",
    "for i in words_dim['clean_words']:\n",
    "    w = ''\n",
    "    t = ''\n",
    "    for j in i:\n",
    "        w+=j[0]+','\n",
    "        t+=j[1]+','\n",
    "    word.loc[len(word)] = w\n",
    "    pos_tag.loc[len(pos_tag)] = t\n",
    "    \n",
    "words_dim['word'] = word\n",
    "words_dim['pos_tag'] = pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = words_dim[['媒体ID', '简介']]\n",
    "words_dim.drop(['简介', 'clean_words'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "sentiment_data['sentiment'] = sentiment_data['简介'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dim = pd.DataFrame({'sentiment':[0,1], 'meaning':['negative', 'positive']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['标题', '简介', 'language_tag'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m标题\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m简介\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanguage_tag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/google_certificate/env/lib/python3.13/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/google_certificate/env/lib/python3.13/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/google_certificate/env/lib/python3.13/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/google_certificate/env/lib/python3.13/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['标题', '简介', 'language_tag'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data.drop(['标题', '简介', 'language_tag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en['标题'] = en['标题'].apply(lambda x: re.sub(r'\\n', '', x))\n",
    "\n",
    "# en['words_pos_tag'] = en['简介'].apply(get_sentiment_words)\n",
    "\n",
    "# # rebuild 简介from words\n",
    "\n",
    "# 简介= pd.Series()\n",
    "\n",
    "# for i in en['words_pos_tag']:\n",
    "#     s = ''\n",
    "#     for j in i:\n",
    "#         s += j[0]+' '\n",
    "#     简介.loc[len(简介)] = s.strip()\n",
    "\n",
    "# en['简介'] = 简介\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_content = en[['媒体ID', '简介']]\n",
    "# ko_content = ko[['媒体ID', '简介']]\n",
    "\n",
    "# content_dim = pd.concat([en_content, ko_content], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_title = en[['媒体ID', '标题']]\n",
    "# ko_title = ko[['媒体ID', '标题']]\n",
    "\n",
    "# title_dim = pd.concat([en_title, ko_title], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dim.to_excel('words_dim.xlsx')\n",
    "data.to_excel('data.xlsx')\n",
    "sentiment_data.to_excel('sentiment_data.xlsx')\n",
    "id_dim.to_excel('id_dim.xlsx')\n",
    "title_dim.to_excel('title_dim.xlsx')\n",
    "sentiment_dim.to_excel('sentiment_dim.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
